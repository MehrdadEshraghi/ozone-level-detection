{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/1998</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10.67</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>5795</td>\n",
       "      <td>-12.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>10330</td>\n",
       "      <td>-55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2/1998</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>8.39</td>\n",
       "      <td>3.84</td>\n",
       "      <td>5805</td>\n",
       "      <td>14.05</td>\n",
       "      <td>29</td>\n",
       "      <td>10275</td>\n",
       "      <td>-55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/3/1998</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.94</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5790</td>\n",
       "      <td>17.9</td>\n",
       "      <td>41.3</td>\n",
       "      <td>10235</td>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/4/1998</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>8.73</td>\n",
       "      <td>10.54</td>\n",
       "      <td>5775</td>\n",
       "      <td>31.15</td>\n",
       "      <td>51.7</td>\n",
       "      <td>10195</td>\n",
       "      <td>-40</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/5/1998</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9   ...    64     65  \\\n",
       "0  1/1/1998  0.8  1.8  2.4  2.1    2  2.1  1.5  1.7  1.9  ...  0.15  10.67   \n",
       "1  1/2/1998  2.8  3.2  3.3  2.7  3.3  3.2  2.9  2.8  3.1  ...  0.48   8.39   \n",
       "2  1/3/1998  2.9  2.8  2.6  2.1  2.2  2.5  2.5  2.7  2.2  ...   0.6   6.94   \n",
       "3  1/4/1998  4.7  3.8  3.7  3.8  2.9  3.1  2.8  2.5  2.4  ...  0.49   8.73   \n",
       "4  1/5/1998  2.6  2.1  1.6  1.4  0.9  1.5  1.2  1.4  1.3  ...     ?      ?   \n",
       "\n",
       "      66    67     68    69     70   71    72   73  \n",
       "0  -1.56  5795  -12.1  17.9  10330  -55     0  0.0  \n",
       "1   3.84  5805  14.05    29  10275  -55     0  0.0  \n",
       "2    9.8  5790   17.9  41.3  10235  -40     0  0.0  \n",
       "3  10.54  5775  31.15  51.7  10195  -40  2.08  0.0  \n",
       "4      ?     ?      ?     ?      ?    ?  0.58  0.0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.data', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Targets and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = data.iloc[:, -1]\n",
    "data = data.iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace missings with 0.0 for mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10.67</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>5795</td>\n",
       "      <td>-12.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>10330</td>\n",
       "      <td>-55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.5</td>\n",
       "      <td>0.48</td>\n",
       "      <td>8.39</td>\n",
       "      <td>3.84</td>\n",
       "      <td>5805</td>\n",
       "      <td>14.05</td>\n",
       "      <td>29</td>\n",
       "      <td>10275</td>\n",
       "      <td>-55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.94</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5790</td>\n",
       "      <td>17.9</td>\n",
       "      <td>41.3</td>\n",
       "      <td>10235</td>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>0.49</td>\n",
       "      <td>8.73</td>\n",
       "      <td>10.54</td>\n",
       "      <td>5775</td>\n",
       "      <td>31.15</td>\n",
       "      <td>51.7</td>\n",
       "      <td>10195</td>\n",
       "      <td>-40</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1    2    3    4    5    6    7    8    9    10  ...     63    64     65  \\\n",
       "0  0.8  1.8  2.4  2.1    2  2.1  1.5  1.7  1.9  2.3  ...  -15.5  0.15  10.67   \n",
       "1  2.8  3.2  3.3  2.7  3.3  3.2  2.9  2.8  3.1  3.4  ...  -14.5  0.48   8.39   \n",
       "2  2.9  2.8  2.6  2.1  2.2  2.5  2.5  2.7  2.2  2.5  ...  -15.9   0.6   6.94   \n",
       "3  4.7  3.8  3.7  3.8  2.9  3.1  2.8  2.5  2.4  3.1  ...  -16.8  0.49   8.73   \n",
       "4  2.6  2.1  1.6  1.4  0.9  1.5  1.2  1.4  1.3  1.4  ...    0.0   0.0    0.0   \n",
       "\n",
       "      66    67     68    69     70   71    72  \n",
       "0  -1.56  5795  -12.1  17.9  10330  -55     0  \n",
       "1   3.84  5805  14.05    29  10275  -55     0  \n",
       "2    9.8  5790   17.9  41.3  10235  -40     0  \n",
       "3  10.54  5775  31.15  51.7  10195  -40  2.08  \n",
       "4    0.0   0.0    0.0   0.0    0.0  0.0  0.58  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in data.columns.values:\n",
    "    data[i].replace(to_replace='?', value=0.0, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     object\n",
       "2     object\n",
       "3     object\n",
       "4     object\n",
       "5     object\n",
       "       ...  \n",
       "68    object\n",
       "69    object\n",
       "70    object\n",
       "71    object\n",
       "72    object\n",
       "Length: 72, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change dtype to float for mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     float64\n",
       "2     float64\n",
       "3     float64\n",
       "4     float64\n",
       "5     float64\n",
       "       ...   \n",
       "68    float64\n",
       "69    float64\n",
       "70    float64\n",
       "71    float64\n",
       "72    float64\n",
       "Length: 72, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in data.columns.values:\n",
    "    data[i] = pd.to_numeric(data[i])\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nirmalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (data - data.mean()) / data.std()\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement logestic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.001, n_iters=1000, l2_rate = 1e-3):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.l2_rate = l2_rate\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # init parameters\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # gradient descent\n",
    "        for _ in range(self.n_iters):\n",
    "            # approximate y with linear combination of weights and x, plus bias\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            \n",
    "            # regularization term\n",
    "            ridge_reg_term = (self.l2_rate / 2 * len(X)) * np.sum(np.square(self.weights))\n",
    "            \n",
    "            linear_model += ridge_reg_term\n",
    "            \n",
    "            # apply sigmoid function\n",
    "            y_predicted = self._sigmoid(linear_model)\n",
    "\n",
    "            # compute gradients\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "            \n",
    "            # update parameters\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self._sigmoid(linear_model)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return np.array(y_predicted_cls)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return np.where(x < 0, np.exp(x)/(1 + np.exp(x)), 1/(1 + np.exp(-x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning Rate: 1, L2_rate: 0.001\n",
      "\t\tMean Train Accuracy: 0.971214003361572\n",
      "\t\tMean Test Accuracy: 0.9712124815234472\n",
      "\t\tSTD: 0.004368126530779725\n",
      "\n",
      "learning Rate: 1, L2_rate: 0.01\n",
      "\t\tMean Train Accuracy: 0.971214003361572\n",
      "\t\tMean Test Accuracy: 0.9712124815234472\n",
      "\t\tSTD: 0.004368126530779725\n",
      "\n",
      "learning Rate: 1, L2_rate: 0.1\n",
      "\t\tMean Train Accuracy: 0.9195645352994214\n",
      "\t\tMean Test Accuracy: 0.900220552921044\n",
      "\t\tSTD: 0.0802198329596239\n",
      "\n",
      "learning Rate: 1, L2_rate: 1.0\n",
      "\t\tMean Train Accuracy: 0.9189728193230899\n",
      "\t\tMean Test Accuracy: 0.8994320645711807\n",
      "\t\tSTD: 0.08057222642151488\n",
      "\n",
      "learning Rate: 1, L2_rate: 10.0\n",
      "\t\tMean Train Accuracy: 0.9189728193230899\n",
      "\t\tMean Test Accuracy: 0.8994320645711807\n",
      "\t\tSTD: 0.08057222642151488\n",
      "\n",
      "learning Rate: 1, L2_rate: 100.0\n",
      "\t\tMean Train Accuracy: 0.9189728193230899\n",
      "\t\tMean Test Accuracy: 0.8994320645711807\n",
      "\t\tSTD: 0.08057222642151488\n",
      "\n",
      "learning Rate: 0.1, L2_rate: 0.001\n",
      "\t\tMean Train Accuracy: 0.971214003361572\n",
      "\t\tMean Test Accuracy: 0.9712124815234472\n",
      "\t\tSTD: 0.004368126530779725\n",
      "\n",
      "learning Rate: 0.1, L2_rate: 0.01\n",
      "\t\tMean Train Accuracy: 0.971214003361572\n",
      "\t\tMean Test Accuracy: 0.9712124815234472\n",
      "\t\tSTD: 0.004368126530779725\n",
      "\n",
      "learning Rate: 0.1, L2_rate: 0.1\n",
      "\t\tMean Train Accuracy: 0.971214003361572\n",
      "\t\tMean Test Accuracy: 0.9712124815234472\n",
      "\t\tSTD: 0.004368126530779725\n",
      "\n",
      "learning Rate: 0.1, L2_rate: 1.0\n",
      "\t\tMean Train Accuracy: 0.9193672966406442\n",
      "\t\tMean Test Accuracy: 0.8998260756034897\n",
      "\t\tSTD: 0.08077090463639841\n",
      "\n",
      "learning Rate: 0.1, L2_rate: 10.0\n",
      "\t\tMean Train Accuracy: 0.9189728193230899\n",
      "\t\tMean Test Accuracy: 0.8994320645711807\n",
      "\t\tSTD: 0.08057222642151488\n",
      "\n",
      "learning Rate: 0.1, L2_rate: 100.0\n",
      "\t\tMean Train Accuracy: 0.9189728193230899\n",
      "\t\tMean Test Accuracy: 0.8994320645711807\n",
      "\t\tSTD: 0.08057222642151488\n",
      "\n",
      "learning Rate: 0.01, L2_rate: 0.001\n",
      "\t\tMean Train Accuracy: 0.971214003361572\n",
      "\t\tMean Test Accuracy: 0.9712124815234472\n",
      "\t\tSTD: 0.004368126530779725\n",
      "\n",
      "learning Rate: 0.01, L2_rate: 0.01\n",
      "\t\tMean Train Accuracy: 0.971214003361572\n",
      "\t\tMean Test Accuracy: 0.9712124815234472\n",
      "\t\tSTD: 0.004368126530779725\n",
      "\n",
      "learning Rate: 0.01, L2_rate: 0.1\n",
      "\t\tMean Train Accuracy: 0.971214003361572\n",
      "\t\tMean Test Accuracy: 0.9712124815234472\n",
      "\t\tSTD: 0.004368126530779725\n",
      "\n",
      "learning Rate: 0.01, L2_rate: 1.0\n",
      "\t\tMean Train Accuracy: 0.9207476173313411\n",
      "\t\tMean Test Accuracy: 0.9045565394174232\n",
      "\t\tSTD: 0.07948252213438557\n",
      "\n",
      "learning Rate: 0.01, L2_rate: 10.0\n",
      "\t\tMean Train Accuracy: 0.9189728193230899\n",
      "\t\tMean Test Accuracy: 0.9002200866357986\n",
      "\t\tSTD: 0.08097292991993556\n",
      "\n",
      "learning Rate: 0.01, L2_rate: 100.0\n",
      "\t\tMean Train Accuracy: 0.9189728193230899\n",
      "\t\tMean Test Accuracy: 0.8998260756034897\n",
      "\t\tSTD: 0.08077090463639841\n",
      "\n",
      "learning Rate: 0.001, L2_rate: 0.001\n",
      "\t\tMean Train Accuracy: 0.9660888308798058\n",
      "\t\tMean Test Accuracy: 0.960956071267037\n",
      "\t\tSTD: 0.018518788360866654\n",
      "\n",
      "learning Rate: 0.001, L2_rate: 0.01\n",
      "\t\tMean Train Accuracy: 0.9660888308798058\n",
      "\t\tMean Test Accuracy: 0.960956071267037\n",
      "\t\tSTD: 0.018518788360866654\n",
      "\n",
      "learning Rate: 0.001, L2_rate: 0.1\n",
      "\t\tMean Train Accuracy: 0.9660888308798058\n",
      "\t\tMean Test Accuracy: 0.960956071267037\n",
      "\t\tSTD: 0.018518788360866654\n",
      "\n",
      "learning Rate: 0.001, L2_rate: 1.0\n",
      "\t\tMean Train Accuracy: 0.9359290454045492\n",
      "\t\tMean Test Accuracy: 0.9254531126871552\n",
      "\t\tSTD: 0.06865276836897338\n",
      "\n",
      "learning Rate: 0.001, L2_rate: 10.0\n",
      "\t\tMean Train Accuracy: 0.9175923819921454\n",
      "\t\tMean Test Accuracy: 0.897461543124391\n",
      "\t\tSTD: 0.08035955200342543\n",
      "\n",
      "learning Rate: 0.001, L2_rate: 100.0\n",
      "\t\tMean Train Accuracy: 0.9181840979684769\n",
      "\t\tMean Test Accuracy: 0.8990375872536265\n",
      "\t\tSTD: 0.08112282477094908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lr in [1, 1e-1, 1e-2, 1e-3]:\n",
    "    for l2 in [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2]:\n",
    "\n",
    "        regressor = LogisticRegression(learning_rate=lr, n_iters=1000, l2_rate = l2)\n",
    "        train_scores, test_scores = list(), list()\n",
    "        kf = KFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "        for train_index, test_index in kf.split(data):\n",
    "            xtrain, xtest = data[train_index], data[test_index]\n",
    "            ytrain, ytest = targets[train_index], targets[test_index]\n",
    "\n",
    "            regressor.fit(xtrain, ytrain)\n",
    "            predictions = regressor.predict(xtest)\n",
    "            train_scores.append(accuracy(ytrain, regressor.predict(xtrain)))\n",
    "            test_scores.append(accuracy(ytest, predictions))\n",
    "\n",
    "        print(f\"learning Rate: {lr}, L2_rate: {l2}\\n\\t\\tMean Train Accuracy: {np.mean(train_scores)}\\n\\t\\tMean Test Accuracy: {np.mean(test_scores)}\\n\\t\\tSTD: {np.std(test_scores)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change in neurons and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 768us/step - loss: 0.0672 - acc: 0.9722\n",
      "27/27 [==============================] - 0s 807us/step - loss: 0.0861 - acc: 0.9775\n",
      "53/53 [==============================] - 0s 732us/step - loss: 0.0783 - acc: 0.9763\n",
      "27/27 [==============================] - 0s 807us/step - loss: 0.1170 - acc: 0.9645\n",
      "53/53 [==============================] - 0s 774us/step - loss: 0.0645 - acc: 0.9769\n",
      "27/27 [==============================] - 0s 798us/step - loss: 0.0890 - acc: 0.9751\n",
      "\n",
      "\tMean Train Accuracy: 0.9751571416854858\n",
      "\tMean Test Accuracy: 0.9723954399426779\n",
      "\tSTD: 0.00566985325268259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_scores, test_scores = list(), list()\n",
    "kf = KFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "for train_index, test_index in kf.split(data):\n",
    "    xtrain, xtest = data[train_index], data[test_index]\n",
    "    ytrain, ytest = targets[train_index], targets[test_index]\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(16, 'relu'),\n",
    "        tf.keras.layers.Dense(2, 'softmax'),\n",
    "    ])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = 'acc')\n",
    "    model.fit(xtrain, ytrain, epochs=50, batch_size=128, verbose = False)\n",
    "    train_scores.append(model.evaluate(xtrain, ytrain)[1])\n",
    "    test_scores.append(model.evaluate(xtest, ytest)[1])\n",
    "\n",
    "print(f\"\\n\\tMean Train Accuracy: {np.mean(train_scores)}\\n\\tMean Test Accuracy: {np.mean(test_scores)}\\n\\tSTD: {np.std(test_scores)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 750us/step - loss: 0.0208 - acc: 0.9959\n",
      "27/27 [==============================] - 0s 784us/step - loss: 0.1418 - acc: 0.9657\n",
      "53/53 [==============================] - 0s 728us/step - loss: 0.0436 - acc: 0.9840\n",
      "27/27 [==============================] - 0s 769us/step - loss: 0.1068 - acc: 0.9633\n",
      "53/53 [==============================] - 0s 802us/step - loss: 0.0405 - acc: 0.9829\n",
      "27/27 [==============================] - 0s 884us/step - loss: 0.1215 - acc: 0.9728\n",
      "\n",
      "\tMean Train Accuracy: 0.9875804980595907\n",
      "\tMean Test Accuracy: 0.9672719041506449\n",
      "\tSTD: 0.004017625848132292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_scores, test_scores = list(), list()\n",
    "kf = KFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "for train_index, test_index in kf.split(data):\n",
    "    xtrain, xtest = data[train_index], data[test_index]\n",
    "    ytrain, ytest = targets[train_index], targets[test_index]\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(32, 'relu'),\n",
    "        tf.keras.layers.Dense(16, 'relu'),\n",
    "        tf.keras.layers.Dense(2, 'softmax'),\n",
    "    ])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = 'acc')\n",
    "    model.fit(xtrain, ytrain, epochs=50, batch_size=128, verbose = False)\n",
    "    train_scores.append(model.evaluate(xtrain, ytrain)[1])\n",
    "    test_scores.append(model.evaluate(xtest, ytest)[1])\n",
    "\n",
    "print(f\"\\n\\tMean Train Accuracy: {np.mean(train_scores)}\\n\\tMean Test Accuracy: {np.mean(test_scores)}\\n\\tSTD: {np.std(test_scores)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 791us/step - loss: 0.0039 - acc: 1.0000\n",
      "27/27 [==============================] - 0s 827us/step - loss: 0.1947 - acc: 0.9539\n",
      "53/53 [==============================] - 0s 791us/step - loss: 0.0120 - acc: 0.9970\n",
      "27/27 [==============================] - 0s 870us/step - loss: 0.1237 - acc: 0.9633\n",
      "53/53 [==============================] - 0s 794us/step - loss: 0.0138 - acc: 0.9965\n",
      "27/27 [==============================] - 0s 922us/step - loss: 0.1499 - acc: 0.9728\n",
      "\n",
      "\tMean Train Accuracy: 0.997831662495931\n",
      "\tMean Test Accuracy: 0.9633317987124125\n",
      "\tSTD: 0.007707888360845271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_scores, test_scores = list(), list()\n",
    "kf = KFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "for train_index, test_index in kf.split(data):\n",
    "    xtrain, xtest = data[train_index], data[test_index]\n",
    "    ytrain, ytest = targets[train_index], targets[test_index]\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(64, 'relu'),\n",
    "        tf.keras.layers.Dense(32, 'relu'),\n",
    "        tf.keras.layers.Dense(16, 'relu'),\n",
    "        tf.keras.layers.Dense(2, 'softmax'),\n",
    "    ])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = 'acc')\n",
    "    model.fit(xtrain, ytrain, epochs=50, batch_size=128, verbose = False)\n",
    "    train_scores.append(model.evaluate(xtrain, ytrain)[1])\n",
    "    test_scores.append(model.evaluate(xtest, ytest)[1])\n",
    "\n",
    "print(f\"\\n\\tMean Train Accuracy: {np.mean(train_scores)}\\n\\tMean Test Accuracy: {np.mean(test_scores)}\\n\\tSTD: {np.std(test_scores)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 826us/step - loss: 5.2859e-04 - acc: 1.0000\n",
      "27/27 [==============================] - 0s 846us/step - loss: 0.2390 - acc: 0.9645\n",
      "53/53 [==============================] - 0s 842us/step - loss: 0.0022 - acc: 1.0000\n",
      "27/27 [==============================] - 0s 883us/step - loss: 0.2081 - acc: 0.9598\n",
      "53/53 [==============================] - 0s 826us/step - loss: 6.5741e-04 - acc: 1.0000\n",
      "27/27 [==============================] - 0s 871us/step - loss: 0.2670 - acc: 0.9704\n",
      "\n",
      "\tMean Train Accuracy: 1.0\n",
      "\tMean Test Accuracy: 0.9649055004119873\n",
      "\tSTD: 0.004355941454447569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_scores, test_scores = list(), list()\n",
    "kf = KFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "for train_index, test_index in kf.split(data):\n",
    "    xtrain, xtest = data[train_index], data[test_index]\n",
    "    ytrain, ytest = targets[train_index], targets[test_index]\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, 'relu'),\n",
    "        tf.keras.layers.Dense(64, 'relu'),\n",
    "        tf.keras.layers.Dense(32, 'relu'),\n",
    "        tf.keras.layers.Dense(16, 'relu'),\n",
    "        tf.keras.layers.Dense(2, 'softmax'),\n",
    "    ])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = 'acc')\n",
    "    model.fit(xtrain, ytrain, epochs=50, batch_size=128, verbose = False)\n",
    "    train_scores.append(model.evaluate(xtrain, ytrain)[1])\n",
    "    test_scores.append(model.evaluate(xtest, ytest)[1])\n",
    "\n",
    "print(f\"\\n\\tMean Train Accuracy: {np.mean(train_scores)}\\n\\tMean Test Accuracy: {np.mean(test_scores)}\\n\\tSTD: {np.std(test_scores)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change in Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 827us/step - loss: 0.0268 - acc: 0.9964\n",
      "27/27 [==============================] - 0s 850us/step - loss: 0.2556 - acc: 0.9598\n",
      "53/53 [==============================] - 0s 842us/step - loss: 0.0189 - acc: 0.9911\n",
      "27/27 [==============================] - 0s 866us/step - loss: 0.2101 - acc: 0.9574\n",
      "53/53 [==============================] - 0s 816us/step - loss: 0.0161 - acc: 0.9947\n",
      "27/27 [==============================] - 0s 845us/step - loss: 0.2442 - acc: 0.9716\n",
      "\n",
      "\tMean Train Accuracy: 0.9940856496493021\n",
      "\tMean Test Accuracy: 0.9629349708557129\n",
      "\tSTD: 0.0062042109755699685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_scores, test_scores = list(), list()\n",
    "kf = KFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "for train_index, test_index in kf.split(data):\n",
    "    xtrain, xtest = data[train_index], data[test_index]\n",
    "    ytrain, ytest = targets[train_index], targets[test_index]\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, 'relu'),\n",
    "        tf.keras.layers.Dense(64, 'relu'),\n",
    "        tf.keras.layers.Dense(32, 'relu'),\n",
    "        tf.keras.layers.Dense(16, 'relu'),\n",
    "        tf.keras.layers.Dense(2, 'softmax'),\n",
    "    ])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-2)\n",
    "    model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = 'acc')\n",
    "    model.fit(xtrain, ytrain, epochs=50, batch_size=128, verbose = False)\n",
    "    train_scores.append(model.evaluate(xtrain, ytrain)[1])\n",
    "    test_scores.append(model.evaluate(xtest, ytest)[1])\n",
    "\n",
    "print(f\"\\n\\tMean Train Accuracy: {np.mean(train_scores)}\\n\\tMean Test Accuracy: {np.mean(test_scores)}\\n\\tSTD: {np.std(test_scores)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 874us/step - loss: 0.1396 - acc: 0.9686\n",
      "27/27 [==============================] - 0s 901us/step - loss: 0.1124 - acc: 0.9764\n",
      "53/53 [==============================] - 0s 846us/step - loss: 0.1206 - acc: 0.9740\n",
      "27/27 [==============================] - 0s 884us/step - loss: 0.1510 - acc: 0.9657\n",
      "53/53 [==============================] - 0s 825us/step - loss: 0.1314 - acc: 0.9710\n",
      "27/27 [==============================] - 0s 884us/step - loss: 0.1293 - acc: 0.9716\n",
      "\n",
      "\tMean Train Accuracy: 0.9712140162785848\n",
      "\tMean Test Accuracy: 0.9712124864260355\n",
      "\tSTD: 0.004368134619110804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_scores, test_scores = list(), list()\n",
    "kf = KFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "for train_index, test_index in kf.split(data):\n",
    "    xtrain, xtest = data[train_index], data[test_index]\n",
    "    ytrain, ytest = targets[train_index], targets[test_index]\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, 'relu'),\n",
    "        tf.keras.layers.Dense(64, 'relu'),\n",
    "        tf.keras.layers.Dense(32, 'relu'),\n",
    "        tf.keras.layers.Dense(16, 'relu'),\n",
    "        tf.keras.layers.Dense(2, 'softmax'),\n",
    "    ])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-1)\n",
    "    model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = 'acc')\n",
    "    model.fit(xtrain, ytrain, epochs=50, batch_size=128, verbose = False)\n",
    "    train_scores.append(model.evaluate(xtrain, ytrain)[1])\n",
    "    test_scores.append(model.evaluate(xtest, ytest)[1])\n",
    "\n",
    "print(f\"\\n\\tMean Train Accuracy: {np.mean(train_scores)}\\n\\tMean Test Accuracy: {np.mean(test_scores)}\\n\\tSTD: {np.std(test_scores)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 857us/step - loss: 0.1407 - acc: 0.9686\n",
      "27/27 [==============================] - 0s 851us/step - loss: 0.1164 - acc: 0.9764\n",
      "53/53 [==============================] - 0s 788us/step - loss: 0.1226 - acc: 0.9740\n",
      "27/27 [==============================] - 0s 845us/step - loss: 0.1561 - acc: 0.9657\n"
     ]
    }
   ],
   "source": [
    "train_scores, test_scores = list(), list()\n",
    "kf = KFold(n_splits=3, shuffle = True, random_state = 42)\n",
    "for train_index, test_index in kf.split(data):\n",
    "    xtrain, xtest = data[train_index], data[test_index]\n",
    "    ytrain, ytest = targets[train_index], targets[test_index]\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, 'relu'),\n",
    "        tf.keras.layers.Dense(64, 'relu'),\n",
    "        tf.keras.layers.Dense(32, 'relu'),\n",
    "        tf.keras.layers.Dense(16, 'relu'),\n",
    "        tf.keras.layers.Dense(2, 'softmax'),\n",
    "    ])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1)\n",
    "    model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = 'acc')\n",
    "    model.fit(xtrain, ytrain, epochs=50, batch_size=128, verbose = False)\n",
    "    train_scores.append(model.evaluate(xtrain, ytrain)[1])\n",
    "    test_scores.append(model.evaluate(xtest, ytest)[1])\n",
    "\n",
    "print(f\"\\n\\tMean Train Accuracy: {np.mean(train_scores)}\\n\\tMean Test Accuracy: {np.mean(test_scores)}\\n\\tSTD: {np.std(test_scores)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Nk5y9w_taeJ-",
    "Prf8J3KkZ4CQ",
    "BD9kpqSuZcIo",
    "2xgVng7xZqKz",
    "meSNirFCZuFJ"
   ],
   "name": "Untitled1.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "08fca6c3b62566c2c29a4f321289ede94cc9386a321f483f6315c291e239c5f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
